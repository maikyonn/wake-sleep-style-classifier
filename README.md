

# Midi Structure Classifier & Style-Aware MIDI Generator (Wake-Sleep)

A research prototype for **structure-aware music modeling**, combining:
1. A **token-level MIDI style classifier** (`A/B/C/D`)
2. A **generative LM** fine-tuned in a **wakeâ€“sleep loop** using style prompts inferred by the frozen classifier.

> Extends a standard MIDI tokenizer with structural tokens like `<A_SECTION>`, `<PROMPT_START>`, and form tags (`<ABA>`, `<ABAC>`, â€¦).

---

## ğŸ“ Repository Layout

```
.
â”œâ”€ aria_generative/model.py     # Transformer blocks (LM / conditional / classifier heads)
â”œâ”€ datamodule.py                # Lightning DataModules for synthetic + real MIDI
â”œâ”€ dataset.py                   # Dataset loading, caching, augmentation
â”œâ”€ MidiClassifierModel.py       # BERT-style token classifier (A/B/C/D)
â”œâ”€ PLGeneratorDM.py             # Generator fine-tuning via frozen classifier
â”œâ”€ tokenizer.py                 # Tokenizer with structural tokens
â”œâ”€ utils.py                     # Prompt builders, parallel I/O, style helpers
â”œâ”€ wake_pl.py                   # Training entrypoint
â””â”€ train_ws_new.sh              # SLURM launcher
```

---

## ğŸ§  Workflow Overview

1. **Tokenization**  
   Adds section and form tokens (`<A_SECTION>`, `<PROMPT_START>`, `<ABA>`).

2. **Classifier (Optional)**  
   BERT-like encoder predicts per-token style `Aâ€“D`, trained on labeled synthetic MIDI.

3. **Wakeâ€“Sleep Fine-Tuning**  
   Freeze classifier â†’ infer latent styles from real MIDI â†’ build prompts â†’ train LM to continue/generate from them.

---

## ğŸ—‚ï¸ Data Layout

```
datasets/<dataset>/
â”œâ”€ midi/*.mid
â””â”€ style/*.txt      # per-MIDI A/B/C/D labels

datasets/<dataset>/data/**/*.mid
```

Data is cached under `./cache`.

---

## âš™ï¸ Installation

Tested with **Python â‰¥ 3.10** and **CUDA GPUs**.

```bash
pip install torch pytorch-lightning transformers wandb tqdm numpy
```

Additional internal deps:
- `ariautils` / `aria` â€” provides AbsTokenizer, MidiDict
- `sageattention` â€” custom attention kernel

---

## ğŸš€ Quickstart

### Single machine:
```bash
python wake_pl.py \
  --data_dir datasets/aria-midi-cycle1/data \
  --devices 1 --num_nodes 1 \
  --file_limit 5000 --max_seq_len 3820 \
  --wandb_mode disabled
```

### Multi-node (SLURM):
```bash
sbatch train_ws_new.sh
```

### Train classifier (optional):
Use `MidiClassifierModel.py` + `SyntheticMidiDataModule` from `datamodule.py`.

---

## ğŸ§© Core Modules

| Component | File | Purpose |
|-----------|------|---------|
| Tokenizer | `tokenizer.py` | Adds structural tokens + helpers |
| Classifier | `MidiClassifierModel.py` | Per-token Aâ€“D style prediction |
| Generator | `PLGeneratorDM.py`, `aria_generative/model.py` | LM fine-tuning via inferred prompts |
| Data | `datamodule.py`, `dataset.py` | Load, augment, and cache MIDI datasets |
| Utils | `utils.py` | Prompt construction, style extraction, I/O helpers |

---

## ğŸ“¤ Outputs

- **Checkpoints**: `./checkpoints/<run>/`
- **Logs**: WandB (or local)
- **CSV summaries**: classifier predictions

---

## ğŸ’» Example

```python
from MidiClassifierModel import MidiClassifier
from tokenizer import MusicTokenizerWithStyle
import torch

tok = MusicTokenizerWithStyle()
model = MidiClassifier(vocab_size=tok.vocab_size).eval()

out = model.evaluate_sequence(torch.randint(0, tok.vocab_size, (2,512)))
print(out['style_tokens'][0][:64])
```
