
â¸»


# Midi Structure Classifier & Style-Aware MIDI Generator (Wake-Sleep)

A research prototype for **structure-aware music modeling**, combining:

1. A **token-level MIDI style classifier** (`A/B/C/D`)
2. A **generative LM** fine-tuned in a **wakeâ€“sleep loop** using style prompts inferred by the frozen classifier.

> Extends a standard MIDI tokenizer with structural tokens like `<A_SECTION>`, `<PROMPT_START>`, and form tags (`<ABA>`, `<ABAC>`, â€¦).

---

## ğŸ“ Repository Layout

.
â”œâ”€ aria_generative/model.py     # Transformer blocks (LM / conditional / classifier heads)
â”œâ”€ datamodule.py                # Lightning DataModules for synthetic + real MIDI
â”œâ”€ dataset.py                   # Dataset loading, caching, augmentation
â”œâ”€ MidiClassifierModel.py       # BERT-style token classifier (A/B/C/D)
â”œâ”€ PLGeneratorDM.py             # Generator fine-tuning via frozen classifier
â”œâ”€ tokenizer.py                 # Tokenizer with structural tokens
â”œâ”€ utils.py                     # Prompt builders, parallel I/O, style helpers
â”œâ”€ wake_pl.py                   # Training entrypoint
â””â”€ train_ws_new.sh              # SLURM launcher

---

## ğŸ§  Workflow Overview

1. **Tokenization**  
   Adds section and form tokens (`<A_SECTION>`, `<PROMPT_START>`, `<ABA>`).

2. **Classifier (Optional)**  
   BERT-like encoder predicts per-token style `Aâ€“D`, trained on labeled synthetic MIDI.

3. **Wakeâ€“Sleep Fine-Tuning**  
   Freeze classifier â†’ infer latent styles from real MIDI â†’ build prompts â†’ train LM to continue/generate from them.

---

## ğŸ—‚ï¸ Data Layout

datasets//
â”œâ”€ midi/.mid
â””â”€ style/.txt      # per-MIDI A/B/C/D labels

datasets//data/**/*.mid

Data is cached under `./cache`.

---

## âš™ï¸ Installation

Tested with **Python â‰¥ 3.10** and **CUDA GPUs**.

```bash
pip install torch pytorch-lightning transformers wandb tqdm numpy

Additional internal deps:
	â€¢	ariautils / aria â€” provides AbsTokenizer, MidiDict
	â€¢	sageattention â€” custom attention kernel

â¸»

ğŸš€ Quickstart

Single machine:

python wake_pl.py \
  --data_dir datasets/aria-midi-cycle1/data \
  --devices 1 --num_nodes 1 \
  --file_limit 5000 --max_seq_len 3820 \
  --wandb_mode disabled

Multi-node (SLURM):

sbatch train_ws_new.sh

Train classifier (optional):
Use MidiClassifierModel.py + SyntheticMidiDataModule from datamodule.py.

â¸»

ğŸ§© Core Modules

Component	File	Purpose
Tokenizer	tokenizer.py	Adds structural tokens + helpers
Classifier	MidiClassifierModel.py	Per-token Aâ€“D style prediction
Generator	PLGeneratorDM.py, aria_generative/model.py	LM fine-tuning via inferred prompts
Data	datamodule.py, dataset.py	Load, augment, and cache MIDI datasets
Utils	utils.py	Prompt construction, style extraction, I/O helpers


â¸»

ğŸ“¤ Outputs
	â€¢	Checkpoints: ./checkpoints/<run>/
	â€¢	Logs: WandB (or local)
	â€¢	CSV summaries: classifier predictions

â¸»

ğŸ’» Example

from MidiClassifierModel import MidiClassifier
from tokenizer import MusicTokenizerWithStyle
import torch

tok = MusicTokenizerWithStyle()
model = MidiClassifier(vocab_size=tok.vocab_size).eval()

out = model.evaluate_sequence(torch.randint(0, tok.vocab_size, (2,512)))
print(out['style_tokens'][0][:64])


â¸»

âš ï¸ Notes
	â€¢	Adjust base-weights/ paths in wake_pl.py.
	â€¢	Remove optional ZClipLightningCallback if missing.
	â€¢	Requires ariautils + sageattention.
	â€¢	Long MIDI files truncated to max_len.

â¸»

ğŸ“œ License

TBD

â¸»

ğŸ“– Citation

If you use this project, please cite appropriately (TBD).

---

Would you like me to make a **slightly more academic variant** next (e.g. with an â€œAbstractâ€, â€œMethodâ€, and â€œResultsâ€ section for arXiv or GitHub research visibility)?
